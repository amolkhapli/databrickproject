
---

## ğŸ—ï¸ Architecture Decisions (Interview-Focused)

### Why Kafka?
- Decouples producers and consumers
- Handles traffic spikes via buffering
- Provides ordered, durable event streams
- Enables horizontal scalability using partitions

### Why Databricks Structured Streaming?
- Native Kafka integration
- Exactly-once processing with Delta Lake
- Built-in state management and watermarking

### Why Delta Lake?
- ACID transactions on data lakes
- Time travel and auditability
- Efficient MERGE support for SCD Type 2

---

## ğŸ¥‰ğŸ¥ˆğŸ¥‡ Medallion Architecture

### Bronze Layer (Raw)
- Stores raw, immutable transaction events
- Acts as the **system of record**
- Enables replay without re-ingesting Kafka data

### Silver Layer (Cleaned)
- Applies data quality rules
- Deduplicates transactions
- Handles late-arriving data using watermarks
- Produces trusted, analytics-ready data

### Gold Layer (Consumption)
Split into **two independent layers** to avoid performance and governance conflicts.

---

## ğŸ¥‡ Gold Layer Strategy

### 1ï¸âƒ£ Gold RT â€“ Operational (SCD Type 1)
**Purpose:** Near real-time dashboards for operations

- Latest state only
- Aggregated metrics per account
- Streaming-based
- Optimized for low latency

**Consumed by:** Power BI (DirectQuery)

---

### 2ï¸âƒ£ Gold Regulatory â€“ Compliance (SCD Type 2)
**Purpose:** Audit, reconciliation, and regulatory reporting

- Full historical records
- Non-destructive updates
- Batch / micro-batch processing
- Long-term retention (7â€“10 years)

**Consumed by:** Power BI (Import mode)

---

## ğŸ“‚ Repository Structure

near-real-time-banking-streaming-platform/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ architecture/
â”‚ â””â”€â”€ near_real_time_streaming_architecture.png
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 00_setup/
â”‚ â”‚ â””â”€â”€ 00_environment_setup.py
â”‚ â”‚
â”‚ â”œâ”€â”€ 01_kafka/
â”‚ â”‚ â””â”€â”€ 01_kafka_event_schema.py
â”‚ â”‚
â”‚ â”œâ”€â”€ 02_bronze/
â”‚ â”‚ â””â”€â”€ 02_kafka_to_bronze_streaming.py
â”‚ â”‚
â”‚ â”œâ”€â”€ 03_silver/
â”‚ â”‚ â””â”€â”€ 03_bronze_to_silver_streaming.py
â”‚ â”‚
â”‚ â”œâ”€â”€ 04_gold_rt/
â”‚ â”‚ â””â”€â”€ 04_silver_to_gold_rt_streaming.py
â”‚ â”‚
â”‚ â””â”€â”€ 05_gold_regulatory/
â”‚ â””â”€â”€ 05_silver_to_gold_reg_scd2.py
â”‚
â”œâ”€â”€ data_simulator/
â”‚ â””â”€â”€ kafka_producer.py
â”‚
â”œâ”€â”€ powerbi/
â”‚ â””â”€â”€ dashboard_design.md
â”‚
â””â”€â”€ docs/
â”œâ”€â”€ interview_explanation.md
â””â”€â”€ assumptions_and_tradeoffs.md

---

## ğŸ”„ End-to-End Data Flow

1. Transaction events are published to Kafka
2. Databricks Structured Streaming ingests data into Bronze Delta tables
3. Bronze data is cleaned and deduplicated into Silver
4. Silver feeds:
   - Gold RT (streaming, SCD Type 1)
   - Gold Regulatory (batch, SCD Type 2)
5. Power BI consumes Gold layers for reporting

---

## â±ï¸ Late Data Handling

- Event-time processing using `transaction_ts`
- Watermark of **10 minutes**
- Prevents unbounded state growth
- Late data beyond watermark can be recovered via Bronze replay

---

## ğŸ” Security & Governance (Conceptual)

- Role-based access per layer
- Masking of PII for operational users
- Restricted access to regulatory data
- Clear data lineage from source to consumption

---

## ğŸš¨ Failure & Recovery Strategy

- Kafka provides durable event storage
- Checkpointing ensures exactly-once processing
- Bronze layer enables full replay
- Regulatory reprocessing does not impact operational dashboards

---

## ğŸ› ï¸ Technologies Used

- Apache Kafka
- Azure Databricks (Structured Streaming)
- PySpark
- Delta Lake
- Azure Data Lake Gen2 (simulated via DBFS)
- Power BI

---

## â–¶ï¸ How to Run (High Level)

1. Start Kafka locally (Docker)
2. Run Kafka producer (`data_simulator/kafka_producer.py`)
3. Execute Databricks notebooks in sequence:
   - 00 â†’ 01 â†’ 02 â†’ 03 â†’ 04 â†’ 05
4. Query Gold tables and connect Power BI

---

## ğŸ¤ Interview Pitch (Short Version)

> â€œI built a near real-time streaming data platform using Kafka and Databricks with a Medallion Architecture.  
> Bronze stores raw immutable data, Silver handles data quality and late data, and Gold is split into operational SCD Type 1 and regulatory SCD Type 2 layers.  
> Power BI consumes these layers using DirectQuery and Import modes respectively, ensuring both performance and compliance.â€

---

## ğŸ“ˆ Target Roles
- Azure Data Engineer
- Azure Data Architect
- Streaming Data Engineer
- BFSI Data Platform Engineer

---

## ğŸ“Œ Disclaimer
This project is created for **learning, hands-on practice, and interview preparation** and simulates enterprise-grade design patterns.

